from transformers import pipeline
from django.conf import settings

_sentiment_analyzer = None
_translator = None
_summarizer = None
_ner_analyzer = None
_spam_analyzer = None

def get_sentiment_model():

    global _sentiment_analyzer
    
    if _sentiment_analyzer is None:
        print("ğŸ“¥ [System] FinBERT ëª¨ë¸ì„ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤... (ìµœì´ˆ 1íšŒ ì‹¤í–‰)")
        # ê¸ˆìœµ íŠ¹í™” ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë“œ
        _sentiment_analyzer = pipeline(
            "text-classification", 
            model="ProsusAI/finbert"
        )
        print("âœ… [System] ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        
    return _sentiment_analyzer

def analyze_news_sentiment(headline: str):
    """
    ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì„ ë°›ì•„ì„œ í˜¸ì¬/ì•…ì¬/ì¤‘ë¦½ì„ íŒë‹¨í•´ì£¼ëŠ” í•¨ìˆ˜
    Input: "Samsung Electronics reports record profits"
    Output: {'label': 'positive', 'score': 0.95, 'korean_label': 'í˜¸ì¬'}
    """
    # 2. ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° 
    analyzer = get_sentiment_model()
    
    # 3. ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰
    # ê²°ê³¼ ì˜ˆì‹œ: [{'label': 'positive', 'score': 0.95}]
    result = analyzer(headline)[0]
    
    label = result['label']
    score = result['score']
    
    if label == 'positive':
        korean_label = 'í˜¸ì¬ ğŸš€'
    elif label == 'negative':
        korean_label = 'ì•…ì¬ ğŸ“‰'
    else:
        korean_label = 'ì¤‘ë¦½ ğŸ˜'
        
    # 5. ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return {
        'original_text': headline,
        'label': label,           # positive/negative/neutral
        'score': round(score * 100, 2), # í™•ë¥ ì„ ë°±ë¶„ìœ¨ë¡œ ë³€í™˜ (0.95 -> 95.0)
        'korean_label': korean_label
    }

# 1. ë²ˆì—­ ëª¨ë¸ ë¡œë“œ (ì˜ì–´ -> í•œêµ­ì–´)
def get_translator():
    global _translator
    if _translator is None:
        print("ğŸ“¥ [System] ë²ˆì—­ ëª¨ë¸ ë¡œë“œ ì¤‘... (NHNDQ NLLB)")
        
        model_id = "NHNDQ/nllb-finetuned-en2ko"
        
        _translator = pipeline(
            "translation", 
            model=model_id, 
            src_lang="eng_Latn",  # ì…ë ¥: ì˜ì–´
            tgt_lang="kor_Hang"   # ì¶œë ¥: í•œêµ­ì–´
        )
    return _translator

# 2. ìš”ì•½ ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ ìš”ì•½)
def get_summarizer():
    global _summarizer
    if _summarizer is None:
        print("ğŸ“¥ [System] ìš”ì•½ ëª¨ë¸ ë¡œë“œ ì¤‘... (KoBART)")
        _summarizer = pipeline("summarization", model="gogamza/kobart-summarization")
    return _summarizer

# 3. íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜: ë²ˆì—­í•˜ê³  -> ìš”ì•½í•œë‹¤
def generate_report(english_news: str):
    """
    Input: 
    ì¶œì²˜ : https://www.investing.com/news/stock-market-news/ford-recalls-over-119000-vehicles-over-engine-block-heater-fire-risk-nhtsa-says-4456865
    
    Jan 21 (Reuters) - Ford Motor is recalling 119,075 vehicles in the U.S. 
    as the engine block heater may crack and leak coolant, potentially causing 
    a short circuit and increasing the risk of a fire when the heater is plugged in, 
    the National Highway Traffic Safety Administration said on Wednesday.

    The recall includes certain Focus, Escape, Explorer and Lincoln MKC vehicles, the agency said.
    Owners are advised not to plug in their block heaters until the vehicles are repaired, NHTSA said, 
    adding that dealers will replace the block heaters free of charge.
    
    Output: 
    """
    # 1ë‹¨ê³„: ë²ˆì—­ (Translation)
    translator = get_translator()
    # ê¸´ ë¬¸ì¥ì€ ì˜ë¦´ ìˆ˜ ìˆì–´ì„œ truncation ì˜µì…˜ ì¶”ê°€
    trans_result = translator(english_news, max_length=512, truncation=True)
    korean_text = trans_result[0]['translation_text']
    
    # 2ë‹¨ê³„: ìš”ì•½ (Summarization) -> ë²ˆì—­ëœ ê²°ê³¼ë¥¼ ì…ë ¥ìœ¼ë¡œ ë„£ìŒ
    summarizer = get_summarizer()
    summary_result = summarizer(korean_text, max_length=100, min_length=30, truncation=True)
    summary_text = summary_result[0]['summary_text']
    
    return {
        'original': english_news,
        'translated': korean_text,
        'summary': summary_text
    }


    
def get_ner_model():
    global _ner_analyzer
    if _ner_analyzer is None:
        print("ğŸ“¥ [System] ê³ ì„±ëŠ¥ NER ëª¨ë¸(Large) ë¡œë“œ ì¤‘... (ì•½ 1.3GB)")
        
        _ner_analyzer = pipeline(
            "ner", 
            model="dbmdz/bert-large-cased-finetuned-conll03-english", 
            aggregation_strategy="simple"
        )
    return _ner_analyzer

def extract_entities(text: str):
    """
    Input: "Elon Musk bought Twitter in San Francisco."
    Output: {'ORG': ['Twitter'], 'PER': ['Elon Musk'], 'LOC': ['San Francisco']}
    """
    analyzer = get_ner_model()
    results = analyzer(text)
    
    # ê²°ê³¼ë¥¼ ê¹”ë”í•˜ê²Œ ë¶„ë¥˜í•´ì„œ ì •ë¦¬í•¨
    entities = {
        "ORG": [],  # ì¡°ì§/íšŒì‚¬
        "PER": [],  # ì‚¬ëŒ
        "LOC": [],  # ì¥ì†Œ
        "MISC": []  # ê¸°íƒ€
    }
    
    for item in results:
        category = item['entity_group'] # ORG, PER, LOC ë“±
        word = item['word']
        
        if category in entities and word not in entities[category]:
            entities[category].append(word)
            
    return entities

def get_spam_model():
    global _spam_analyzer
    if _spam_analyzer is None:
        print("ğŸ“¥ [System] ìŠ¤íŒ¸ íƒì§€ ëª¨ë¸ ë¡œë“œ ì¤‘... (RoBERTa)")
        _spam_analyzer = pipeline(
            "text-classification", 
            model="mshenoda/roberta-spam"
        )
    return _spam_analyzer

def detect_spam(text: str):
    """
    Input: "You won $1000 cash prize! Click here."
    Output: {'label': 'SPAM', 'score': 98.5, 'korean_label': 'ìŠ¤íŒ¸(ìœ„í—˜)'}
    """
    analyzer = get_spam_model()
    
    # ê²°ê³¼ ì˜ˆì‹œ: [{'label': 'LABEL_1', 'score': 0.98}] 
    # (LABEL_1 = ìŠ¤íŒ¸, LABEL_0 = ì •ìƒ)
    result = analyzer(text)[0]
    
    label_code = result['label']
    score = result['score']
    
    if label_code == 'LABEL_1':
        final_label = 'spam'
        korean_label = 'ğŸš« ìŠ¤íŒ¸ / í”¼ì‹± (ìœ„í—˜)'
    else:
        final_label = 'ham'
        korean_label = 'âœ… ì •ìƒ ë©”ì‹œì§€ (ì•ˆì „)'
        
    return {
        'label': final_label,  
        'score': round(score * 100, 2),
        'korean_label': korean_label
    }