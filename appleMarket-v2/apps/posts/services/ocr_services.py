import os
import sys
import cv2
import numpy as np
import re
from paddleocr import PaddleOCR

# [ê²½ë¡œ ì„¤ì •]
if os.name == 'nt':
    target_cache_dir = 'C:/paddle_cache'
    if not os.path.exists(target_cache_dir):
        try: os.makedirs(target_cache_dir)
        except: pass
    os.environ['USERPROFILE'] = target_cache_dir
    os.environ['HOME'] = target_cache_dir
    os.environ['PADDLE_HOME'] = target_cache_dir
    os.environ['PADDLEX_HOME'] = target_cache_dir

# OCR ëª¨ë¸ ë¡œë“œ
ocr = PaddleOCR(use_angle_cls=True, lang='korean')

def extract_nutrition_info(image_file):
    # 1. ì´ë¯¸ì§€ ì½ê¸°
    file_bytes = np.frombuffer(image_file.read(), np.uint8)
    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
    if image is None: return {}

    # ---------------------------------------------------------
    # [ì „ì²˜ë¦¬] 5ì¤‘ í•„í„° (ì¸ì‹ ìžì²´ëŠ” ìž˜ ë˜ë¯€ë¡œ ìœ ì§€)
    # ---------------------------------------------------------
    processed_images = []
    
    # ì—¬ë°± ì¶”ê°€
    image_padded = cv2.copyMakeBorder(image, 50, 50, 50, 50, cv2.BORDER_CONSTANT, value=(255, 255, 255))
    
    # 1. ì›ë³¸
    gray = cv2.cvtColor(image_padded, cv2.COLOR_BGR2GRAY)
    gray_resized = cv2.resize(gray, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)
    processed_images.append(gray_resized)
    
    # 2. ë°˜ì „
    gray_inv = cv2.bitwise_not(gray_resized)
    processed_images.append(gray_inv)
    
    # 3. ì´ì§„í™”
    _, binary = cv2.threshold(gray_resized, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    processed_images.append(binary)
    processed_images.append(cv2.bitwise_not(binary)) # ë°˜ì „ ì´ì§„í™”

    # 4. í°ìƒ‰ ì¶”ì¶œ
    hsv = cv2.cvtColor(image_padded, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv, np.array([0, 0, 150]), np.array([180, 50, 255]))
    processed_images.append(cv2.bitwise_not(mask))

    # ---------------------------------------------------------
    # [OCR ì‹¤í–‰]
    # ---------------------------------------------------------
    all_text_list = []
    for img in processed_images:
        try:
            result = ocr.ocr(img, cls=False)
            if result and result[0]:
                for line in result[0]:
                    if line and len(line) >= 2 and line[1]:
                        if line[1][1] > 0.5:
                            all_text_list.append(line[1][0])
        except: continue
    
    full_text = " ".join(all_text_list)
    print(f"ðŸ” [OCR í†µí•© ë°ì´í„°] {full_text}")

    data = { 'calorie': 0, 'carbo': 0, 'protein': 0, 'fat': 0, 'hashtag': '#ê¸°íƒ€' }

    # ---------------------------------------------------------
    # [í•µì‹¬] ì œí’ˆ íƒ€ìž… íŒë‹¨ (ìƒˆìš°íƒ• vs í¬ìŠ¤í‹±)
    # ---------------------------------------------------------
    # "ë©´", "ëˆ„ë“¤", "ìƒˆìš°íƒ•", "ë¼ë©´" ì¤‘ í•˜ë‚˜ë¼ë„ ìžˆìœ¼ë©´ ë¼ë©´ ëª¨ë“œ ë°œë™
    is_noodle_mode = any(k in full_text for k in ['ìƒˆìš°íƒ•', 'ëˆ„ë“¤', 'ë©´', 'ë¼ë©´', 'êµ­ìˆ˜'])

    # ---------------------------------------------------------
    # [íŒŒì‹± ë¡œì§] ëª¨ë“œì— ë”°ë¥¸ ì´ì›í™” ì²˜ë¦¬
    # ---------------------------------------------------------
    def parse_value_split(text, keywords, nutrient_type):
        # 1. %ê°€ ë¶™ì€ ìˆ«ìžëŠ” ì•„ì˜ˆ ì§€ì›Œë²„ë¦¼ (ê°€ìž¥ í™•ì‹¤í•œ ë°©ë²•)
        # ì˜ˆ: "28%" -> " " (ê³µë°±)
        text = re.sub(r'\d+(?:\.\d+)?\s*%', ' ', text)
        
        # 2. gë¥¼ 9ë¡œ ì½ëŠ” ì˜¤ì¸ì‹ ë°©ì§€
        text = re.sub(r'(\d)\s*9\s', r'\1g ', text)
        
        target_text = ""
        for keyword in keywords:
            if keyword in text:
                target_text = text.split(keyword, 1)[1]
                break
        
        if not target_text: return 0

        # 3. ìˆ«ìž ì¶”ì¶œ
        # íŠ¹ìˆ˜ë¬¸ìžë¥¼ ê³µë°±ìœ¼ë¡œ ë°”ê¿ˆ (ì  . ì€ ì‚´ë¦¼)
        cleaned_text = re.sub(r'[^\d.]', ' ', target_text)
        tokens = cleaned_text.split()
        
        valid_numbers = []
        for token in tokens:
            try:
                if token.count('.') > 1: # 1.6.3 -> 1.6
                    token = token.split('.')[0] + '.' + token.split('.')[1]
                val = float(token)
                
                # ì¹¼ë¡œë¦¬ 2000 ë¬´ì¡°ê±´ ì œì™¸
                if nutrient_type == 'calorie' and val == 2000: continue
                
                valid_numbers.append(val)
            except: continue

        if not valid_numbers: return 0

        # -----------------------------------------------------
        # [ëª¨ë“œë³„ ê²°ì • ë¡œì§] ì—¬ê¸°ê°€ í•µì‹¬ìž…ë‹ˆë‹¤
        # -----------------------------------------------------
        val1 = valid_numbers[0]
        
        # [Case 1: ë¼ë©´ ëª¨ë“œ (ìƒˆìš°íƒ•)] -> í•©ì¹˜ê¸° & ì†Œìˆ˜ì  ì ê·¹ ë³´ì •
        if is_noodle_mode:
            # íƒ„ìˆ˜í™”ë¬¼: ìˆ«ìžê°€ ëŠê²¨ìžˆìœ¼ë©´ í•©ì¹¨ (2 9 -> 29)
            if nutrient_type == 'carbo':
                if val1 < 10 and len(valid_numbers) >= 2:
                    val2 = valid_numbers[1]
                    merged = float(f"{int(val1)}{int(val2)}")
                    if merged <= 150: val1 = merged
            
            # ì§€ë°©/ë‹¨ë°±ì§ˆ: 10 ë„˜ìœ¼ë©´ ë¬´ì¡°ê±´ ì˜¤ì¸ì‹ìœ¼ë¡œ ê°„ì£¼ (ë¼ë©´ íŠ¹ì„±ìƒ 16g ì§€ë°©ì€ ë“œë¬¾ -> 1.6)
            if nutrient_type in ['fat', 'protein']:
                if val1 >= 10: val1 /= 10.0

        # [Case 2: ìŠ¤ë‚µ ëª¨ë“œ (í¬ìŠ¤í‹±)] -> ì²« ë²ˆì§¸ ìˆ«ìžë§Œ ì‹ ë¢°
        else:
            # íƒ„ìˆ˜í™”ë¬¼/ë‹¨ë°±ì§ˆ/ì§€ë°©: ë’¤ì— ìˆ«ìžê°€ ë” ìžˆì–´ë„ ë¬´ì‹œí•¨ (ì´ë¯¸ %ëŠ” ìœ„ì—ì„œ ì§€ì› ìœ¼ë¯€ë¡œ)
            # ë‹¨ë°±ì§ˆ/ì§€ë°©ì´ 35 ë„˜ìœ¼ë©´ ì†Œìˆ˜ì  ëˆ„ë½ìœ¼ë¡œ ì˜ì‹¬ (38 -> 3.8)
            if nutrient_type in ['fat', 'protein']:
                if val1 > 35: val1 /= 10.0
            
            # íƒ„ìˆ˜í™”ë¬¼ì€ ê·¸ëƒ¥ ë‘  (60ì€ 60ìž„)

        # ê³µí†µ ì˜¤ì¸ì‹ ë°©ì§€ (ë„ˆë¬´ í° ê°’)
        if nutrient_type == 'carbo' and val1 > 300: val1 /= 10.0

        return val1

    # 1. ì¹¼ë¡œë¦¬
    cal_match = re.search(r'(\d{2,4})\s*(?:kcal|Kcal)', full_text)
    if cal_match:
        try:
            val = float(cal_match.group(1))
            if val != 2000: data['calorie'] = val
        except: pass
        
    if data['calorie'] == 0:
        data['calorie'] = parse_value_split(full_text, ['ì¹¼ë¡œë¦¬', 'ì—´ëŸ‰'], 'calorie')

    # 2. íƒ„ìˆ˜í™”ë¬¼
    data['carbo'] = parse_value_split(full_text, ['íƒ„ìˆ˜í™”ë¬¼', 'íƒ„ìˆ˜', 'í™”ë¬¼'], 'carbo')
    
    # 3. ë‹¨ë°±ì§ˆ
    data['protein'] = parse_value_split(full_text, ['ë‹¨ë°±ì§ˆ', 'ë‹¨ë°±'], 'protein')
    
    # 4. ì§€ë°©
    clean_fat_text = full_text.replace('íŠ¸ëžœìŠ¤ì§€ë°©', '').replace('í¬í™”ì§€ë°©', '')
    data['fat'] = parse_value_split(clean_fat_text, ['ì§€ë°©'], 'fat')

    # í•´ì‹œíƒœê·¸
    if is_noodle_mode:
        data['hashtag'] = '#ì»µë¼ë©´ #ë¼ë©´'
    elif 'ê³¼ìž' in full_text or 'ìŠ¤ë‚µ' in full_text or 'ìœ íƒ•' in full_text:
        data['hashtag'] = '#ê³¼ìž'
    elif 'ìŒë£Œ' in full_text or 'ì»¤í”¼' in full_text:
        data['hashtag'] = '#ìŒë£Œ'
    elif 'ë¹µ' in full_text:
        data['hashtag'] = '#ë¹µ'
    elif data['protein'] >= 10:
        data['hashtag'] = '#ê³ ë‹¨ë°±'

    return data